{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b40ec03",
   "metadata": {},
   "source": [
    "# Apple Financial and Social Analysis Dataset\n",
    "## Exploratory Data Analysis (EDA)\n",
    "\n",
    "**Author:** Diyar Erol  \n",
    "**Repository:** [DiyarErol/Apple_Financial_and_Social_Analysis_Dataset](https://github.com/DiyarErol/Apple_Financial_and_Social_Analysis_Dataset)  \n",
    "**Date:** December 2025\n",
    "\n",
    "### Overview\n",
    "This notebook provides a comprehensive exploratory data analysis of the Apple Financial and Social Analysis Dataset. We will examine the structure, distributions, correlations, and key insights from the data to prepare for feature engineering and machine learning modeling.\n",
    "\n",
    "### Dataset Description\n",
    "- **Features:** 80+ technical indicators, financial metrics, and sentiment scores\n",
    "- **Time Period:** 2015–2025 (AAPL stock data)\n",
    "- **Sample Size:** 2,696 trading records\n",
    "- **Target Variable:** Apple stock price prediction (closing price)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a686d90",
   "metadata": {},
   "source": [
    "## 1. Library Imports and Environment Setup\n",
    "\n",
    "In this section, we import all necessary libraries and configure the visualization environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c363e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import essential libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "# Configure visualization settings\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"✅ Libraries imported successfully!\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Matplotlib version: {plt.matplotlib.__version__}\")\n",
    "print(f\"Seaborn version: {sns.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc90d06",
   "metadata": {},
   "source": [
    "## 2. Load Dataset\n",
    "\n",
    "Load the main datasets from the data directory. We will use the enhanced feature dataset which includes technical indicators and sentiment scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc826f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data path (relative to notebooks directory)\n",
    "import os\n",
    "data_path = os.path.join(os.path.dirname(os.getcwd()), 'data')\n",
    "\n",
    "# Load the enhanced feature dataset\n",
    "df = pd.read_csv(os.path.join(data_path, 'apple_feature_enhanced.csv'))\n",
    "\n",
    "print(f\"✅ Dataset loaded successfully!\")\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Columns: {len(df.columns)} features\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1dec86",
   "metadata": {},
   "source": [
    "## 3. Dataset Overview\n",
    "\n",
    "Examine the basic structure, dimensions, and statistical summary of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32d6565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic information about the dataset\n",
    "print(\"=\" * 80)\n",
    "print(\"DATASET OVERVIEW\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nShape: {df.shape[0]} rows × {df.shape[1]} columns\")\n",
    "print(f\"Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"DATA TYPES AND INFO\")\n",
    "print(\"=\" * 80)\n",
    "df.info()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STATISTICAL SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "df.describe().round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840c643f",
   "metadata": {},
   "source": [
    "## 4. Missing Value and Data Type Inspection\n",
    "\n",
    "Check for missing values and validate data types across all features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363e972f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"=\" * 80)\n",
    "print(\"MISSING VALUES ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "missing_count = df.isnull().sum()\n",
    "missing_percent = (missing_count / len(df)) * 100\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Count': missing_count,\n",
    "    'Percentage': missing_percent\n",
    "}).sort_values('Missing Count', ascending=False)\n",
    "\n",
    "missing_df_filtered = missing_df[missing_df['Missing Count'] > 0]\n",
    "if len(missing_df_filtered) > 0:\n",
    "    print(missing_df_filtered)\n",
    "else:\n",
    "    print(\"✅ No missing values detected in the dataset!\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"DATA TYPE DISTRIBUTION\")\n",
    "print(\"=\" * 80)\n",
    "print(df.dtypes.value_counts())\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"NUMERIC COLUMNS SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "print(f\"Total numeric columns: {len(numeric_cols)}\")\n",
    "print(f\"Numeric columns: {list(numeric_cols[:10])}...\") if len(numeric_cols) > 10 else print(f\"Numeric columns: {list(numeric_cols)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deeaf474",
   "metadata": {},
   "source": [
    "## 5. Basic Statistical Analysis\n",
    "\n",
    "Analyze key financial metrics and price trends in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5f5b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify key columns\n",
    "print(\"=\" * 80)\n",
    "print(\"KEY FINANCIAL METRICS ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Check for price-related columns\n",
    "price_cols = [col for col in df.columns if 'close' in col.lower() or 'price' in col.lower()]\n",
    "print(f\"\\nPrice/Close columns found: {price_cols}\")\n",
    "\n",
    "if price_cols:\n",
    "    close_col = price_cols[0]\n",
    "    print(f\"\\n### Price Statistics ({close_col}):\")\n",
    "    print(f\"Mean: ${df[close_col].mean():.2f}\")\n",
    "    print(f\"Median: ${df[close_col].median():.2f}\")\n",
    "    print(f\"Std Dev: ${df[close_col].std():.2f}\")\n",
    "    print(f\"Min: ${df[close_col].min():.2f}\")\n",
    "    print(f\"Max: ${df[close_col].max():.2f}\")\n",
    "    print(f\"Range: ${df[close_col].max() - df[close_col].min():.2f}\")\n",
    "\n",
    "# Check for return-related columns\n",
    "return_cols = [col for col in df.columns if 'return' in col.lower()]\n",
    "print(f\"\\nReturn columns found: {return_cols}\")\n",
    "\n",
    "if return_cols:\n",
    "    for ret_col in return_cols[:3]:\n",
    "        print(f\"\\n### Return Statistics ({ret_col}):\")\n",
    "        print(f\"Mean: {df[ret_col].mean():.6f}\")\n",
    "        print(f\"Std Dev: {df[ret_col].std():.6f}\")\n",
    "        print(f\"Min: {df[ret_col].min():.6f}\")\n",
    "        print(f\"Max: {df[ret_col].max():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b411fe",
   "metadata": {},
   "source": [
    "## 6. Feature Correlation Heatmap\n",
    "\n",
    "Visualize correlations between numeric features to identify relationships and potential multicollinearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc472d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation matrix for numeric features\n",
    "numeric_df = df.select_dtypes(include=[np.number])\n",
    "correlation_matrix = numeric_df.corr()\n",
    "\n",
    "# Create correlation heatmap (limit to top features for readability)\n",
    "plt.figure(figsize=(16, 12))\n",
    "# Select top 20 features by variance\n",
    "top_features = numeric_df.var().nlargest(20).index\n",
    "sns.heatmap(correlation_matrix.loc[top_features, top_features], \n",
    "            annot=False, cmap='coolwarm', center=0, \n",
    "            square=True, linewidths=0.5, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Feature Correlation Heatmap (Top 20 Features by Variance)', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"✅ Correlation heatmap generated!\")\n",
    "print(f\"\\nTop 10 most correlated feature pairs:\")\n",
    "# Get top correlations (excluding diagonal)\n",
    "corr_pairs = []\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i+1, len(correlation_matrix.columns)):\n",
    "        corr_pairs.append({\n",
    "            'Feature 1': correlation_matrix.columns[i],\n",
    "            'Feature 2': correlation_matrix.columns[j],\n",
    "            'Correlation': correlation_matrix.iloc[i, j]\n",
    "        })\n",
    "corr_pairs_df = pd.DataFrame(corr_pairs).sort_values('Correlation', ascending=False, key=abs)\n",
    "print(corr_pairs_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03ce167",
   "metadata": {},
   "source": [
    "## 7. Visual Insights\n",
    "\n",
    "Explore distributions and trends through visualization using Matplotlib and Seaborn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74627d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize distribution of top numeric features\n",
    "top_numeric_features = numeric_df.var().nlargest(6).index\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, col in enumerate(top_numeric_features):\n",
    "    axes[idx].hist(df[col], bins=50, edgecolor='black', alpha=0.7, color='steelblue')\n",
    "    axes[idx].set_title(f'Distribution of {col}', fontweight='bold')\n",
    "    axes[idx].set_xlabel(col)\n",
    "    axes[idx].set_ylabel('Frequency')\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"✅ Distribution histograms generated!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ec6d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time series plot of key price metric\n",
    "if price_cols:\n",
    "    plt.figure(figsize=(16, 6))\n",
    "    plt.plot(df.index, df[price_cols[0]], linewidth=2, color='navy', alpha=0.8)\n",
    "    plt.title(f'{price_cols[0]} Over Time', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Time Index')\n",
    "    plt.ylabel('Price (USD)')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"✅ Time series plot of {price_cols[0]} generated!\")\n",
    "\n",
    "# Box plots for outlier detection\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"OUTLIER DETECTION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "for idx, col in enumerate(top_numeric_features[:3]):\n",
    "    axes[idx].boxplot(df[col])\n",
    "    axes[idx].set_title(f'Box Plot: {col}', fontweight='bold')\n",
    "    axes[idx].set_ylabel(col)\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"✅ Box plots generated for outlier detection!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ead07f2",
   "metadata": {},
   "source": [
    "## 8. Summary of Findings\n",
    "\n",
    "Key insights and observations from the exploratory data analysis."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
